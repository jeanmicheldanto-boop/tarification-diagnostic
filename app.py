import streamlit as st
import os
from dotenv import load_dotenv
import openai

# ğŸ” Charger la clÃ© API
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI(api_key=openai.api_key)

# âš™ï¸ Configuration de la page Streamlit
st.set_page_config(page_title="BMSE â€“ Diagnostic tarification", page_icon="ğŸ“Š")
st.title("ğŸ“Š Auto-diagnostic : la maturitÃ© de votre organisation de tarification")
st.markdown(
    "Cet Ã©change rapide vous aide Ã  Ã©valuer votre fonctionnement actuel autour des fonctions "
    "d'instruction des budgets, du contrÃ´le des comptes administratifs (CA) et du pilotage. "
    "Il vous suggÃ¨re des pistes dâ€™optimisation. *(DurÃ©e : 5 Ã  7 minutes)*"
)

# ğŸ” Initialiser l'historique
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [
        {"role": "system", "content": """Tu es un assistant spÃ©cialisÃ© dans la tarification des ESSMS (EPRD, ERRD, contrÃ´le des comptes administratifs).
Tu discutes avec un interlocuteur issu d'une autoritÃ© de tarification (dÃ©partement, ARS, DREETS, ou autre), et ton objectif est de lâ€™amener Ã  faire le point sur sa maturitÃ© organisationnelle, Ã  travers quelques questions structurÃ©es.
Ton ton est professionnel, complice mais jamais familier, et tu glisses parfois une remarque lÃ©gÃ¨re mais toujours respectueuse.

Voici la logique de ton comportement :

- Ã€ la premiÃ¨re rÃ©ponse, identifie si la personne est issue dâ€™une autoritÃ© de tarification.
  Si oui, rÃ©ponds : "Parfait, vous Ãªtes au bon endroit ğŸ˜Š Ce diagnostic a Ã©tÃ© pensÃ© pour les professionnels comme vous."
  Sinon, rÃ©ponds : "Ravi de voir que la tarification suscite lâ€™intÃ©rÃªt, mÃªme au-delÃ  des fonctions classiques dâ€™instruction budgÃ©taire."

- Ensuite, pose les questions suivantes, une par une, avec relance complice :
1. ÃŠtes-vous aujourdâ€™hui dans les dÃ©lais rÃ©glementaires ou acceptables pour lâ€™instruction des EPRD/ERRD et la notification des dÃ©cisions ?
   â†’ Relance : On sait que la pÃ©riode est souvent tendueâ€¦
2. Disposez-vous dâ€™un cadrage clair pour orienter vos dÃ©cisions tarifaires ? (dÃ©libÃ©rations, note de cadrage, doctrine interneâ€¦)
   â†’ Relance : Parfois, Ã§a repose sur des habitudes plus que sur une ligne stratÃ©gique, non ?
3. Pensez-vous que vos outils et vos compÃ©tences internes sont bien adaptÃ©s au volume et Ã  la technicitÃ© des ESSMS que vous suivez ?
   â†’ Relance : Câ€™est souvent un dÃ©fi avec les structures complexes ou les formats multiples.
4. ÃŠtes-vous plutÃ´t fervent pratiquant de la tarification Ã  la ressourceâ€¦ ou adepte dâ€™une approche plus classique ?
   â†’ Relance : Pas de jugement, les deux se dÃ©fendent ğŸ˜‰
5. Et une derniÃ¨re pour la route : avez-vous dÃ©jÃ  rejetÃ© des dÃ©penses en instruisant les CA ou les EPRD ?
   â†’ Relance : Moins de 5 fois ? Câ€™est peut-Ãªtre signe dâ€™un contrÃ´le trop gÃ©nÃ©reux ğŸ˜‡

- Ã€ la fin de lâ€™Ã©change, propose une synthÃ¨se structurÃ©e, contextualisÃ©e et personnalisÃ©e des axes de progrÃ¨s.

- Termine par un message sobre mais engageant :

"Merci pour cet Ã©change. Votre organisation prÃ©sente sans doute des atouts solides, mais aussi quelques leviers dâ€™optimisation possibles.  
BMSE accompagne les autoritÃ©s de tarification dans ces Ã©volutions, avec une approche sobre, rÃ©aliste et adaptÃ©e Ã  vos contraintes.  
ğŸ‘‰ Pour en savoir plus : https://bmse.jimdosite.com"""}
    ]

# ğŸ’¬ Afficher l'historique
for msg in st.session_state.chat_history[1:]:
    if msg["role"] == "user":
        st.markdown(f"**Vous** : {msg['content']}")
    elif msg["role"] == "assistant":
        st.markdown(f"**Mon compagnon Tarif** : {msg['content']}")

# ğŸ–ï¸ Saisie utilisateur
user_input = st.chat_input("âœï¸ Votre rÃ©ponse")

# ğŸ¤– Traitement OpenAI (GPT-4)
if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    with st.spinner("Analyse en cours..."):
        response = client.chat.completions.create(
            model="gpt-4",
            messages=st.session_state.chat_history
        )
        assistant_reply = response.choices[0].message.content

    st.session_state.chat_history.append({"role": "assistant", "content": assistant_reply})
    st.markdown(f"**Mon compagnon Tarif** : {assistant_reply}")
